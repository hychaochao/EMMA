phoenix-srun: job 3877579 queued and waiting for resources
phoenix-srun: job 3877579 has been allocated resources
phoenix-srun: Job 3877579 scheduled successfully!
Current QUOTA_TYPE is [reserved], which means the job has occupied quota in RESERVED_TOTAL under your partition.
Current PHX_PRIORITY is normal

[root] Loading dataset mm-reasoning/EMMA-test100, subject: ['Math']
Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]Generating test split: 100%|██████████| 100/100 [00:00<00:00, 1893.75 examples/s]
[root] Loading config
[root] Loading local model /mnt/petrelfs/share_data/quxiaoye/models/InternVL2_5-78B
[transformers_modules.InternVL2_5-78B.configuration_internvl_chat] vision_select_layer: -1
[transformers_modules.InternVL2_5-78B.configuration_internvl_chat] ps_version: v2
[transformers_modules.InternVL2_5-78B.configuration_internvl_chat] min_dynamic_patch: 1
[transformers_modules.InternVL2_5-78B.configuration_internvl_chat] max_dynamic_patch: 12
/mnt/petrelfs/haoyunzhuo/anaconda3/envs/intern/lib/python3.9/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
[transformers_modules.InternVL2_5-78B.modeling_internvl_chat] num_image_token: 256
[transformers_modules.InternVL2_5-78B.modeling_internvl_chat] ps_version: v2
Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/33 [00:10<05:27, 10.24s/it]Loading checkpoint shards:   6%|▌         | 2/33 [00:17<04:24,  8.52s/it]Loading checkpoint shards:   9%|▉         | 3/33 [00:23<03:46,  7.54s/it]Loading checkpoint shards:  12%|█▏        | 4/33 [00:30<03:31,  7.28s/it]Loading checkpoint shards:  15%|█▌        | 5/33 [00:37<03:15,  6.98s/it]Loading checkpoint shards:  18%|█▊        | 6/33 [00:44<03:13,  7.16s/it]Loading checkpoint shards:  21%|██        | 7/33 [00:51<03:03,  7.06s/it]Loading checkpoint shards:  24%|██▍       | 8/33 [01:00<03:11,  7.64s/it]Loading checkpoint shards:  27%|██▋       | 9/33 [01:06<02:54,  7.27s/it]Loading checkpoint shards:  30%|███       | 10/33 [01:13<02:42,  7.07s/it]Loading checkpoint shards:  33%|███▎      | 11/33 [01:20<02:31,  6.87s/it]Loading checkpoint shards:  36%|███▋      | 12/33 [01:26<02:23,  6.83s/it]Loading checkpoint shards:  39%|███▉      | 13/33 [01:33<02:17,  6.86s/it]Loading checkpoint shards:  42%|████▏     | 14/33 [01:40<02:09,  6.82s/it]Loading checkpoint shards:  45%|████▌     | 15/33 [01:47<02:04,  6.91s/it]Loading checkpoint shards:  48%|████▊     | 16/33 [01:55<02:03,  7.29s/it]Loading checkpoint shards:  52%|█████▏    | 17/33 [02:02<01:52,  7.03s/it]Loading checkpoint shards:  55%|█████▍    | 18/33 [02:09<01:46,  7.08s/it]Loading checkpoint shards:  58%|█████▊    | 19/33 [02:15<01:36,  6.92s/it]Loading checkpoint shards:  61%|██████    | 20/33 [02:22<01:29,  6.91s/it]Loading checkpoint shards:  64%|██████▎   | 21/33 [02:29<01:21,  6.82s/it]Loading checkpoint shards:  67%|██████▋   | 22/33 [02:36<01:16,  6.96s/it]Loading checkpoint shards:  70%|██████▉   | 23/33 [02:43<01:08,  6.85s/it]Loading checkpoint shards:  73%|███████▎  | 24/33 [02:51<01:05,  7.31s/it]Loading checkpoint shards:  76%|███████▌  | 25/33 [02:58<00:57,  7.21s/it]Loading checkpoint shards:  79%|███████▉  | 26/33 [03:05<00:50,  7.19s/it]Loading checkpoint shards:  82%|████████▏ | 27/33 [03:12<00:41,  6.98s/it]Loading checkpoint shards:  85%|████████▍ | 28/33 [03:18<00:33,  6.68s/it]Loading checkpoint shards:  88%|████████▊ | 29/33 [03:24<00:26,  6.69s/it]Loading checkpoint shards:  91%|█████████ | 30/33 [03:31<00:19,  6.61s/it]Loading checkpoint shards:  94%|█████████▍| 31/33 [03:37<00:13,  6.52s/it]Loading checkpoint shards:  97%|█████████▋| 32/33 [03:43<00:06,  6.21s/it]Loading checkpoint shards: 100%|██████████| 33/33 [03:47<00:00,  5.56s/it]Loading checkpoint shards: 100%|██████████| 33/33 [03:47<00:00,  6.89s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[root] Model loaded!
[root] Results already exists.
[root] Reading results/test-time-compute/InternVL2_5_Math_16.json
[root] Found existing results file with 43 problems with valid responses. Skipping these problems...
[root] Starting to generate.....
  0%|          | 0/100 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
[root] Save results to results/test-time-compute/InternVL2_5_Math_16.json
 44%|████▍     | 44/100 [23:35<30:01, 32.17s/it]Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
