phoenix-srun: job 3877583 queued and waiting for resources
phoenix-srun: job 3877583 has been allocated resources
phoenix-srun: Job 3877583 scheduled successfully!
Current QUOTA_TYPE is [reserved], which means the job has occupied quota in RESERVED_TOTAL under your partition.
Current PHX_PRIORITY is normal

[root] Loading dataset mm-reasoning/EMMA-test100, subject: ['Physics']
Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]Generating test split: 100%|██████████| 100/100 [00:00<00:00, 1443.56 examples/s]
[root] Loading config
[root] Loading local model /mnt/petrelfs/share_data/quxiaoye/models/InternVL2_5-78B
[transformers_modules.InternVL2_5-78B.configuration_internvl_chat] vision_select_layer: -1
[transformers_modules.InternVL2_5-78B.configuration_internvl_chat] ps_version: v2
[transformers_modules.InternVL2_5-78B.configuration_internvl_chat] min_dynamic_patch: 1
[transformers_modules.InternVL2_5-78B.configuration_internvl_chat] max_dynamic_patch: 12
/mnt/petrelfs/haoyunzhuo/anaconda3/envs/intern/lib/python3.9/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
[transformers_modules.InternVL2_5-78B.modeling_internvl_chat] num_image_token: 256
[transformers_modules.InternVL2_5-78B.modeling_internvl_chat] ps_version: v2
Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/33 [00:08<04:41,  8.81s/it]Loading checkpoint shards:   6%|▌         | 2/33 [00:15<03:51,  7.48s/it]Loading checkpoint shards:   9%|▉         | 3/33 [00:21<03:31,  7.06s/it]Loading checkpoint shards:  12%|█▏        | 4/33 [00:27<03:12,  6.64s/it]Loading checkpoint shards:  15%|█▌        | 5/33 [00:33<02:58,  6.37s/it]Loading checkpoint shards:  18%|█▊        | 6/33 [00:39<02:48,  6.25s/it]Loading checkpoint shards:  21%|██        | 7/33 [00:45<02:40,  6.16s/it]Loading checkpoint shards:  24%|██▍       | 8/33 [00:53<02:42,  6.49s/it]Loading checkpoint shards:  27%|██▋       | 9/33 [00:59<02:32,  6.34s/it]Loading checkpoint shards:  30%|███       | 10/33 [01:05<02:25,  6.34s/it]Loading checkpoint shards:  33%|███▎      | 11/33 [01:11<02:15,  6.15s/it]Loading checkpoint shards:  36%|███▋      | 12/33 [01:17<02:09,  6.15s/it]Loading checkpoint shards:  39%|███▉      | 13/33 [01:23<02:00,  6.05s/it]Loading checkpoint shards:  42%|████▏     | 14/33 [01:29<01:55,  6.08s/it]Loading checkpoint shards:  45%|████▌     | 15/33 [01:35<01:48,  6.03s/it]Loading checkpoint shards:  48%|████▊     | 16/33 [01:42<01:50,  6.52s/it]Loading checkpoint shards:  52%|█████▏    | 17/33 [01:48<01:40,  6.31s/it]Loading checkpoint shards:  55%|█████▍    | 18/33 [01:54<01:32,  6.18s/it]Loading checkpoint shards:  58%|█████▊    | 19/33 [02:00<01:24,  6.03s/it]Loading checkpoint shards:  61%|██████    | 20/33 [02:05<01:17,  5.96s/it]Loading checkpoint shards:  64%|██████▎   | 21/33 [02:11<01:10,  5.85s/it]Loading checkpoint shards:  67%|██████▋   | 22/33 [02:17<01:04,  5.83s/it]Loading checkpoint shards:  70%|██████▉   | 23/33 [02:23<00:59,  5.91s/it]Loading checkpoint shards:  73%|███████▎  | 24/33 [02:30<00:57,  6.41s/it]Loading checkpoint shards:  76%|███████▌  | 25/33 [02:36<00:49,  6.16s/it]Loading checkpoint shards:  79%|███████▉  | 26/33 [02:42<00:42,  6.09s/it]Loading checkpoint shards:  82%|████████▏ | 27/33 [02:48<00:36,  6.07s/it]Loading checkpoint shards:  85%|████████▍ | 28/33 [02:54<00:29,  5.90s/it]Loading checkpoint shards:  88%|████████▊ | 29/33 [03:00<00:23,  6.00s/it]Loading checkpoint shards:  91%|█████████ | 30/33 [03:05<00:17,  5.93s/it]Loading checkpoint shards:  94%|█████████▍| 31/33 [03:12<00:11,  5.96s/it]Loading checkpoint shards:  97%|█████████▋| 32/33 [03:17<00:05,  5.70s/it]Loading checkpoint shards: 100%|██████████| 33/33 [03:20<00:00,  5.07s/it]Loading checkpoint shards: 100%|██████████| 33/33 [03:20<00:00,  6.08s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[root] Model loaded!
[root] Results already exists.
[root] Reading results/test-time-compute/InternVL2_5_Physics_16.json
[root] Found existing results file with 25 problems with valid responses. Skipping these problems...
[root] Starting to generate.....
  0%|          | 0/100 [00:00<?, ?it/s]  9%|▉         | 9/100 [00:00<00:01, 58.81it/s] 23%|██▎       | 23/100 [00:00<00:01, 64.32it/s]Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
 23%|██▎       | 23/100 [00:17<00:01, 64.32it/s]Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
[root] Save results to results/test-time-compute/InternVL2_5_Physics_16.json
 26%|██▌       | 26/100 [17:00<1:13:06, 59.27s/it]Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
